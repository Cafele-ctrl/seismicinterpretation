import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Input, Concatenate, UpSampling2D
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import cv2
import os
import pickle
import io
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, jaccard_score
from sklearn.model_selection import train_test_split
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import json

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lise SÃ­smica AvanÃ§ada com CNN",
    page_icon="ğŸ›¢ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# TÃ­tulo principal
st.title("ğŸ›¢ï¸ Sistema AvanÃ§ado de AnÃ¡lise de Imagens SÃ­smicas com CNN")
st.markdown("### IdentificaÃ§Ã£o de PadrÃµes para ExploraÃ§Ã£o de Hidrocarbonetos com Suporte a Masks")

class SeismicCNN:
    def __init__(self, input_shape=(128, 128, 3), num_classes=3, use_masks=False, use_transfer_learning=False):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.use_masks = use_masks
        self.use_transfer_learning = use_transfer_learning
        self.model = None
        self.history = None
        self.data_generator = None
        
    def build_model(self):
        """ConstrÃ³i a arquitetura da CNN com opÃ§Ãµes avanÃ§adas"""
        if self.use_transfer_learning:
            return self._build_transfer_learning_model()
        elif self.use_masks:
            return self._build_unet_model()
        else:
            return self._build_standard_cnn()
    
    def _build_standard_cnn(self):
        """CNN padrÃ£o melhorada"""
        model = tf.keras.Sequential([
            # Primeira camada convolucional
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape, padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # Segunda camada convolucional
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # Terceira camada convolucional
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # Quarta camada convolucional
            tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # Global Average Pooling
            tf.keras.layers.GlobalAveragePooling2D(),
            
            # Camadas densas
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(self.num_classes, activation='softmax')
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model = model
        return model
    
    def _build_transfer_learning_model(self):
        """Modelo com Transfer Learning usando ResNet50"""
        base_model = ResNet50(
            weights='imagenet',
            include_top=False,
            input_shape=self.input_shape
        )
        
        # Congelar camadas iniciais
        base_model.trainable = False
        
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(self.num_classes, activation='softmax')
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model = model
        return model
    
    def _build_unet_model(self):
        """Modelo U-Net para segmentaÃ§Ã£o com masks"""
        inputs = Input(shape=self.input_shape)
        
        # Encoder
        conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
        conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
        
        conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
        conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
        
        conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
        conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
        
        conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
        conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
        drop4 = Dropout(0.5)(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
        
        conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
        conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
        drop5 = Dropout(0.5)(conv5)
        
        # Decoder
        up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
        merge6 = Concatenate()([drop4, up6])
        conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
        conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)
        
        up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
        merge7 = Concatenate()([conv3, up7])
        conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
        conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)
        
        up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
        merge8 = Concatenate()([conv2, up8])
        conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
        conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)
        
        up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
        merge9 = Concatenate()([conv1, up9])
        conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
        conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)
        conv9 = Conv2D(2, 3, activation='relu', padding='same')(conv9)
        
        # SaÃ­da para segmentaÃ§Ã£o
        segmentation_output = Conv2D(self.num_classes, 1, activation='softmax', name='segmentation')(conv9)
        
        # Branch para classificaÃ§Ã£o
        gap = tf.keras.layers.GlobalAveragePooling2D()(conv5)
        dense1 = Dense(512, activation='relu')(gap)
        dense1 = BatchNormalization()(dense1)
        dense1 = Dropout(0.5)(dense1)
        classification_output = Dense(self.num_classes, activation='softmax', name='classification')(dense1)
        
        model = Model(inputs=inputs, outputs=[segmentation_output, classification_output])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
            loss={
                'segmentation': 'categorical_crossentropy',
                'classification': 'categorical_crossentropy'
            },
            loss_weights={'segmentation': 0.7, 'classification': 0.3},
            metrics={
                'segmentation': ['accuracy'],
                'classification': ['accuracy']
            }
        )
        
        self.model = model
        return model
    
    def setup_data_augmentation(self):
        """Configura data augmentation especÃ­fico para dados sÃ­smicos"""
        self.data_generator = ImageDataGenerator(
            rotation_range=15,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True,
            vertical_flip=False,
            zoom_range=0.1,
            brightness_range=[0.8, 1.2],
            fill_mode='reflect'
        )
    
    def preprocess_image(self, image, target_size=(128, 128)):
        """PrÃ©-processa uma imagem"""
        if isinstance(image, str):
            img = cv2.imread(image)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        elif hasattr(image, 'read'):
            image.seek(0)
            file_bytes = np.asarray(bytearray(image.read()), dtype=np.uint8)
            img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        else:
            img = np.array(image)
            if len(img.shape) == 3 and img.shape[2] == 3:
                pass
            elif len(img.shape) == 3 and img.shape[2] == 4:
                img = img[:, :, :3]
        
        if not isinstance(img, np.ndarray):
            img = np.array(img)
        
        img = cv2.resize(img, target_size)
        img = img.astype(np.float32) / 255.0
        return img
    
    def predict_single_image(self, image):
        """Faz prediÃ§Ã£o para uma Ãºnica imagem"""
        processed_img = self.preprocess_image(image)
        processed_img = np.expand_dims(processed_img, axis=0)
        
        if self.use_masks:
            predictions = self.model.predict(processed_img)
            return predictions[1]  # Retorna classificaÃ§Ã£o
        else:
            prediction = self.model.predict(processed_img)
            return prediction
    
    def generate_gradcam(self, image, class_index, layer_name=None):
        """Gera Grad-CAM para explicabilidade"""
        processed_img = self.preprocess_image(image)
        processed_img = np.expand_dims(processed_img, axis=0)
        
        if layer_name is None:
            for layer in reversed(self.model.layers):
                if len(layer.output_shape) == 4:
                    layer_name = layer.name
                    break
        
        grad_model = tf.keras.models.Model(
            [self.model.inputs], 
            [self.model.get_layer(layer_name).output, self.model.output]
        )
        
        with tf.GradientTape() as tape:
            conv_outputs, predictions = grad_model(processed_img)
            loss = predictions[:, class_index]
        
        output = conv_outputs[0]
        grads = tape.gradient(loss, conv_outputs)[0]
        
        gate_f = tf.cast(output > 0, 'float32')
        gate_r = tf.cast(grads > 0, 'float32')
        guided_grads = gate_f * gate_r * grads
        
        weights = tf.reduce_mean(guided_grads, axis=(0, 1))
        cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)
        
        cam = cv2.resize(cam.numpy(), (128, 128))
        cam = np.maximum(cam, 0)
        cam = cam / cam.max()
        
        return cam

# FunÃ§Ãµes auxiliares - CORRIGIDAS PARA EVITAR PROBLEMAS DE DIMENSÃƒO
def load_images_and_labels(image_files, labels, target_size=(128, 128)):
    """Carrega apenas imagens - FUNÃ‡ÃƒO SEGURA"""
    images = []
    processed_labels = []
    valid_indices = []
    
    for i, (img_file, label) in enumerate(zip(image_files, labels)):
        try:
            img_file.seek(0)
            image = Image.open(img_file)
            image = image.convert('RGB')
            image = image.resize(target_size)
            
            img_array = np.array(image).astype(np.float32) / 255.0
            images.append(img_array)
            processed_labels.append(label)
            valid_indices.append(i)
            
        except Exception as e:
            st.error(f"Erro ao processar {img_file.name}: {str(e)}")
            continue
    
    return np.array(images), np.array(processed_labels), valid_indices

def load_images_masks_and_labels(image_files, mask_files, labels, target_size=(128, 128)):
    """Carrega imagens + masks - FUNÃ‡ÃƒO SEGURA COM VALIDAÃ‡ÃƒO"""
    if len(image_files) != len(mask_files) or len(image_files) != len(labels):
        raise ValueError(f"DimensÃµes incompatÃ­veis: {len(image_files)} imagens, {len(mask_files)} masks, {len(labels)} labels")
    
    images = []
    masks = []
    processed_labels = []
    valid_indices = []
    
    for i, (img_file, mask_file, label) in enumerate(zip(image_files, mask_files, labels)):
        try:
            # Processar imagem
            img_file.seek(0)
            image = Image.open(img_file)
            image = image.convert('RGB')
            image = image.resize(target_size)
            img_array = np.array(image).astype(np.float32) / 255.0
            
            # Processar mask
            mask_file.seek(0)
            mask = Image.open(mask_file)
            mask = mask.convert('L')
            mask = mask.resize(target_size)
            mask_array = np.array(mask)
            
            # Normalizar mask para classes 0-2
            mask_array = (mask_array / 127.5).astype(np.uint8)
            mask_array = np.clip(mask_array, 0, 2)
            mask_categorical = tf.keras.utils.to_categorical(mask_array, 3)
            
            # SÃ³ adiciona se ambos foram processados com sucesso
            images.append(img_array)
            masks.append(mask_categorical)
            processed_labels.append(label)
            valid_indices.append(i)
            
        except Exception as e:
            st.error(f"Erro ao processar {img_file.name} ou {mask_file.name}: {str(e)}")
            continue
    
    if len(images) == 0:
        raise ValueError("Nenhuma imagem/mask foi processada com sucesso")
    
    return np.array(images), np.array(masks), np.array(processed_labels), valid_indices

def safe_metrics_calculation(y_true, y_pred, class_names):
    """Calcula mÃ©tricas de forma segura, evitando erros de dimensÃ£o"""
    try:
        # Garantir que ambos sÃ£o arrays numpy 1D
        y_true = np.array(y_true).flatten()
        y_pred = np.array(y_pred).flatten()
        
        # Debug info
        st.write(f"**Debug MÃ©tricas:**")
        st.write(f"- y_true shape: {y_true.shape}, unique values: {np.unique(y_true)}")
        st.write(f"- y_pred shape: {y_pred.shape}, unique values: {np.unique(y_pred)}")
        
        # Verificar se tÃªm o mesmo tamanho
        if len(y_true) != len(y_pred):
            st.error(f"Erro: y_true ({len(y_true)}) != y_pred ({len(y_pred)})")
            return None, None, None, None
        
        # Calcular mÃ©tricas
        accuracy = accuracy_score(y_true, y_pred)
        
        # RelatÃ³rio de classificaÃ§Ã£o com tratamento de erro
        try:
            report = classification_report(y_true, y_pred, output_dict=True, zero_division=0, labels=[0, 1, 2])
            precision_avg = report['macro avg']['precision']
            recall_avg = report['macro avg']['recall']
        except Exception as e:
            st.warning(f"Erro no relatÃ³rio de classificaÃ§Ã£o: {str(e)}")
            precision_avg = 0.0
            recall_avg = 0.0
            report = None
        
        # Matriz de confusÃ£o
        try:
            cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])
        except Exception as e:
            st.warning(f"Erro na matriz de confusÃ£o: {str(e)}")
            cm = None
        
        return accuracy, precision_avg, recall_avg, cm, report
        
    except Exception as e:
        st.error(f"Erro geral no cÃ¡lculo de mÃ©tricas: {str(e)}")
        return None, None, None, None, None

def plot_training_history(history, use_masks=False):
    """Plota o histÃ³rico de treinamento"""
    try:
        if use_masks:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('AcurÃ¡cia - ClassificaÃ§Ã£o', 'Perda - ClassificaÃ§Ã£o', 
                              'AcurÃ¡cia - SegmentaÃ§Ã£o', 'Perda - SegmentaÃ§Ã£o'),
            )
            
            epochs = range(1, len(history.history['classification_accuracy']) + 1)
            
            # ClassificaÃ§Ã£o
            fig.add_trace(go.Scatter(x=list(epochs), y=history.history['classification_accuracy'], 
                                    mode='lines', name='Treino', line=dict(color='blue')), row=1, col=1)
            if 'val_classification_accuracy' in history.history:
                fig.add_trace(go.Scatter(x=list(epochs), y=history.history['val_classification_accuracy'], 
                                        mode='lines', name='ValidaÃ§Ã£o', line=dict(color='red')), row=1, col=1)
            
            fig.add_trace(go.Scatter(x=list(epochs), y=history.history['classification_loss'], 
                                    mode='lines', name='Treino', line=dict(color='blue')), row=1, col=2)
            if 'val_classification_loss' in history.history:
                fig.add_trace(go.Scatter(x=list(epochs), y=history.history['val_classification_loss'], 
                                        mode='lines', name='ValidaÃ§Ã£o', line=dict(color='red')), row=1, col=2)
            
            # SegmentaÃ§Ã£o
            fig.add_trace(go.Scatter(x=list(epochs), y=history.history['segmentation_accuracy'], 
                                    mode='lines', name='Treino', line=dict(color='green')), row=2, col=1)
            if 'val_segmentation_accuracy' in history.history:
                fig.add_trace(go.Scatter(x=list(epochs), y=history.history['val_segmentation_accuracy'], 
                                        mode='lines', name='ValidaÃ§Ã£o', line=dict(color='orange')), row=2, col=1)
            
            fig.add_trace(go.Scatter(x=list(epochs), y=history.history['segmentation_loss'], 
                                    mode='lines', name='Treino', line=dict(color='green')), row=2, col=2)
            if 'val_segmentation_loss' in history.history:
                fig.add_trace(go.Scatter(x=list(epochs), y=history.history['val_segmentation_loss'], 
                                        mode='lines', name='ValidaÃ§Ã£o', line=dict(color='orange')), row=2, col=2)
        else:
            fig = make_subplots(rows=1, cols=2, subplot_titles=('AcurÃ¡cia', 'Perda'))
            
            epochs = range(1, len(history.history['accuracy']) + 1)
            
            fig.add_trace(go.Scatter(x=list(epochs), y=history.history['accuracy'], 
                                    mode='lines', name='Treino', line=dict(color='blue')), row=1, col=1)
            if 'val_accuracy' in history.history:
                fig.add_trace(go.Scatter(x=list(epochs), y=history.history['val_accuracy'], 
                                        mode='lines', name='ValidaÃ§Ã£o', line=dict(color='red')), row=1, col=1)
            
            fig.add_trace(go.Scatter(x=list(epochs), y=history.history['loss'], 
                                    mode='lines', name='Treino', line=dict(color='blue')), row=1, col=2)
            if 'val_loss' in history.history:
                fig.add_trace(go.Scatter(x=list(epochs), y=history.history['val_loss'], 
                                        mode='lines', name='ValidaÃ§Ã£o', line=dict(color='red')), row=1, col=2)
        
        fig.update_layout(height=600, showlegend=False, title_text="MÃ©tricas de Treinamento")
        return fig
        
    except Exception as e:
        st.error(f"Erro ao plotar histÃ³rico de treinamento: {str(e)}")
        return None

def plot_confusion_matrix_safe(cm, class_names):
    """Plota matriz de confusÃ£o de forma segura"""
    try:
        if cm is None:
            st.warning("Matriz de confusÃ£o nÃ£o disponÃ­vel")
            return None
            
        fig = px.imshow(cm, 
                        labels=dict(x="Predito", y="Real", color="Contagem"),
                        x=class_names,
                        y=class_names,
                        color_continuous_scale='Blues',
                        text_auto=True)
        fig.update_layout(title="Matriz de ConfusÃ£o")
        return fig
        
    except Exception as e:
        st.error(f"Erro ao criar matriz de confusÃ£o: {str(e)}")
        return None

def plot_gradcam_overlay(original_image, gradcam, alpha=0.6):
    """Cria sobreposiÃ§Ã£o de Grad-CAM"""
    try:
        gradcam = (gradcam * 255).astype(np.uint8)
        gradcam = cv2.applyColorMap(gradcam, cv2.COLORMAP_JET)
        gradcam = cv2.cvtColor(gradcam, cv2.COLOR_BGR2RGB)
        
        if original_image.shape[:2] != gradcam.shape[:2]:
            original_image = cv2.resize(original_image, (gradcam.shape[1], gradcam.shape[0]))
        
        overlay = cv2.addWeighted(original_image, 1-alpha, gradcam, alpha, 0)
        return overlay
        
    except Exception as e:
        st.error(f"Erro ao criar Grad-CAM: {str(e)}")
        return original_image

# Interface Streamlit Principal
def main():
    # Sidebar
    st.sidebar.header("âš™ï¸ ConfiguraÃ§Ãµes")
    
    # DefiniÃ§Ã£o das classes
    class_names = ['NÃ£o ReservatÃ³rio', 'PossÃ­vel ReservatÃ³rio', 'ProvÃ¡vel ReservatÃ³rio']
    
    # ConfiguraÃ§Ãµes do modelo
    st.sidebar.subheader("ğŸ§  Arquitetura do Modelo")
    use_masks = st.sidebar.checkbox("Usar Masks para SegmentaÃ§Ã£o", value=False)
    use_transfer_learning = st.sidebar.checkbox("Transfer Learning (ResNet50)", value=False)
    use_data_augmentation = st.sidebar.checkbox("Data Augmentation", value=True)
    
    # SeÃ§Ã£o de upload de dados
    st.header("ğŸ“ Carregamento de Dados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Dados de Treinamento")
        train_files = st.file_uploader(
            "Carregar imagens de treino",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            key="train"
        )
        
        # Upload de masks se habilitado - CORRIGIDO
        train_masks = None
        if use_masks:
            if train_files:
                st.info(f"ğŸ¯ Modo SegmentaÃ§Ã£o: Carregue {len(train_files)} masks correspondentes")
                train_masks = st.file_uploader(
                    f"Masks de treino ({len(train_files)} necessÃ¡rias)",
                    type=['png', 'jpg', 'jpeg'],
                    accept_multiple_files=True,
                    key="train_masks",
                    help="Cada mask deve corresponder a uma imagem na mesma ordem"
                )
                
                if train_masks:
                    if len(train_masks) == len(train_files):
                        st.success(f"âœ… {len(train_masks)} masks vÃ¡lidas carregadas")
                        
                        # Mostrar correspondÃªncia
                        with st.expander("Ver correspondÃªncia Imagem-Mask"):
                            for i, (img, mask) in enumerate(zip(train_files, train_masks)):
                                st.write(f"{i+1}. {img.name} â†” {mask.name}")
                                
                    else:
                        st.error(f"âŒ Erro: {len(train_masks)} masks â‰  {len(train_files)} imagens")
                        st.info("ğŸ’¡ Carregue exatamente a mesma quantidade de masks e imagens")
                        train_masks = None
            else:
                st.info("ğŸ“¤ Primeiro carregue as imagens de treino")
        
        if train_files:
            st.success(f"âœ… {len(train_files)} imagens carregadas")
            
            # Labels para dados de treino
            st.subheader("RÃ³tulos das Imagens de Treino")
            train_labels = []
            for i, file in enumerate(train_files):
                label = st.selectbox(
                    f"Classe para {file.name}:",
                    options=[0, 1, 2],
                    format_func=lambda x: class_names[x],
                    key=f"train_label_{i}"
                )
                train_labels.append(label)
    
    with col2:
        st.subheader("Dados de Teste")
        test_files = st.file_uploader(
            "Carregar imagens de teste",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            key="test"
        )
        
        # Upload de masks de teste - CORRIGIDO
        test_masks = None
        if use_masks:
            if test_files:
                st.info(f"ğŸ¯ Modo SegmentaÃ§Ã£o: Carregue {len(test_files)} masks correspondentes")
                test_masks = st.file_uploader(
                    f"Masks de teste ({len(test_files)} necessÃ¡rias)",
                    type=['png', 'jpg', 'jpeg'],
                    accept_multiple_files=True,
                    key="test_masks",
                    help="Cada mask deve corresponder a uma imagem na mesma ordem"
                )
                
                if test_masks:
                    if len(test_masks) == len(test_files):
                        st.success(f"âœ… {len(test_masks)} masks vÃ¡lidas carregadas")
                        
                        # Mostrar correspondÃªncia
                        with st.expander("Ver correspondÃªncia Imagem-Mask"):
                            for i, (img, mask) in enumerate(zip(test_files, test_masks)):
                                st.write(f"{i+1}. {img.name} â†” {mask.name}")
                                
                    else:
                        st.error(f"âŒ Erro: {len(test_masks)} masks â‰  {len(test_files)} imagens")
                        st.info("ğŸ’¡ Carregue exatamente a mesma quantidade de masks e imagens")
                        test_masks = None
            else:
                st.info("ğŸ“¤ Primeiro carregue as imagens de teste")
        
        if test_files:
            st.success(f"âœ… {len(test_files)} imagens carregadas")
            
            # Labels para dados de teste
            st.subheader("RÃ³tulos das Imagens de Teste")
            test_labels = []
            for i, file in enumerate(test_files):
                label = st.selectbox(
                    f"Classe para {file.name}:",
                    options=[0, 1, 2],
                    format_func=lambda x: class_names[x],
                    key=f"test_label_{i}"
                )
                test_labels.append(label)
    
    # ParÃ¢metros de treinamento
    st.sidebar.subheader("ParÃ¢metros de Treinamento")
    epochs = st.sidebar.slider("NÃºmero de Ã‰pocas", 10, 200, 50)
    batch_size = st.sidebar.slider("Batch Size", 4, 32, 16)
    
    # Status do modo de treinamento
    if use_masks:
        has_valid_train_masks = train_masks and len(train_masks) == len(train_files) if train_files else False
        if has_valid_train_masks:
            st.sidebar.success("âœ… Modo: SegmentaÃ§Ã£o + ClassificaÃ§Ã£o")
        else:
            st.sidebar.warning("âš ï¸ Aguardando masks vÃ¡lidas")
    else:
        st.sidebar.info("â„¹ï¸ Modo: ClassificaÃ§Ã£o")
    
    # BotÃ£o de treinamento
    if st.button("ğŸš€ Iniciar Treinamento", type="primary"):
        if not train_files or len(train_labels) != len(train_files):
            st.error("âŒ Carregue as imagens e defina os rÃ³tulos!")
            return
        
        # Determinar modo de treinamento
        train_with_masks = use_masks and train_masks and len(train_masks) == len(train_files)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # CARREGAR DADOS
            status_text.text("Carregando dados...")
            progress_bar.progress(20)
            
            if train_with_masks:
                st.info("ğŸ¯ Iniciando treinamento com segmentaÃ§Ã£o...")
                X_train, masks_train, y_train, valid_train_indices = load_images_masks_and_labels(
                    train_files, train_masks, train_labels
                )
                st.write(f"âœ… Carregados: {len(X_train)} pares imagem-mask")
            else:
                st.info("ğŸ¯ Iniciando treinamento com classificaÃ§Ã£o...")
                X_train, y_train, valid_train_indices = load_images_and_labels(train_files, train_labels)
                masks_train = None
                st.write(f"âœ… Carregadas: {len(X_train)} imagens")
            
            # PREPARAR DADOS
            status_text.text("Preparando dados...")
            progress_bar.progress(40)
            
            y_train_cat = tf.keras.utils.to_categorical(y_train, 3)
            
            # DIVISÃƒO TREINO/VALIDAÃ‡ÃƒO
            if train_with_masks:
                # COM MASKS
                X_train_split, X_val_split, y_train_split, y_val_split, masks_train_split, masks_val_split = train_test_split(
                    X_train, y_train_cat, masks_train, test_size=0.2, random_state=42
                )
                st.write(f"âœ… DivisÃ£o: {len(X_train_split)} treino, {len(X_val_split)} validaÃ§Ã£o (com masks)")
            else:
                # SEM MASKS
                X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
                    X_train, y_train_cat, test_size=0.2, random_state=42
                )
                st.write(f"âœ… DivisÃ£o: {len(X_train_split)} treino, {len(X_val_split)} validaÃ§Ã£o")
            
            # CRIAR MODELO
            status_text.text("Construindo modelo...")
            progress_bar.progress(60)
            
            cnn = SeismicCNN(
                use_masks=train_with_masks,
                use_transfer_learning=use_transfer_learning
            )
            model = cnn.build_model()
            
            st.write(f"âœ… Modelo criado: {model.count_params():,} parÃ¢metros")
            
            if use_data_augmentation:
                cnn.setup_data_augmentation()
                st.write("âœ… Data augmentation configurado")
            
            # TREINAMENTO
            status_text.text("Treinando modelo...")
            progress_bar.progress(80)
            
            callbacks = [
                tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),
                tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7)
            ]
            
            if train_with_masks:
                # Treinamento com masks
                history = model.fit(
                    X_train_split,
                    {'segmentation': masks_train_split, 'classification': y_train_split},
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_data=(X_val_split, {'segmentation': masks_val_split, 'classification': y_val_split}),
                    callbacks=callbacks,
                    verbose=1
                )
            else:
                # Treinamento padrÃ£o
                if use_data_augmentation and cnn.data_generator:
                    train_generator = cnn.data_generator.flow(X_train_split, y_train_split, batch_size=batch_size)
                    history = model.fit(
                        train_generator,
                        epochs=epochs,
                        validation_data=(X_val_split, y_val_split),
                        callbacks=callbacks,
                        verbose=1,
                        steps_per_epoch=len(X_train_split) // batch_size
                    )
                else:
                    history = model.fit(
                        X_train_split, y_train_split,
                        epochs=epochs,
                        batch_size=batch_size,
                        validation_data=(X_val_split, y_val_split),
                        callbacks=callbacks,
                        verbose=1
                    )
            
            progress_bar.progress(100)
            status_text.text("âœ… Treinamento concluÃ­do!")
            
            # Salvar no session state
            st.session_state.model = model
            st.session_state.history = history
            st.session_state.class_names = class_names
            st.session_state.cnn = cnn
            st.session_state.use_masks = train_with_masks
            st.session_state.valid_train_indices = valid_train_indices
            
            st.success("ğŸ‰ Modelo treinado com sucesso!")
            
        except Exception as e:
            st.error(f"âŒ Erro durante o treinamento: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
    
    # Resultados do Treinamento
    if 'model' in st.session_state:
        st.header("ğŸ“Š Resultados do Treinamento")
        
        # GrÃ¡ficos de treinamento
        use_masks_trained = st.session_state.get('use_masks', False)
        history_fig = plot_training_history(st.session_state.history, use_masks_trained)
        if history_fig:
            st.plotly_chart(history_fig, use_container_width=True)
        
        # AvaliaÃ§Ã£o no conjunto de teste
        if test_files and len(test_labels) == len(test_files):
            st.subheader("ğŸ¯ AvaliaÃ§Ã£o no Conjunto de Teste")
            
            try:
                # Carregar dados de teste
                test_with_masks = use_masks_trained and test_masks and len(test_masks) == len(test_files)
                
                if test_with_masks:
                    X_test, masks_test, y_test, valid_test_indices = load_images_masks_and_labels(
                        test_files, test_masks, test_labels
                    )
                    st.write(f"âœ… Teste carregado: {len(X_test)} pares imagem-mask")
                else:
                    X_test, y_test, valid_test_indices = load_images_and_labels(test_files, test_labels)
                    masks_test = None
                    st.write(f"âœ… Teste carregado: {len(X_test)} imagens")
                
                # PrediÃ§Ãµes
                if use_masks_trained:
                    predictions = st.session_state.model.predict(X_test, verbose=0)
                    y_pred = np.argmax(predictions[1], axis=1)  # ClassificaÃ§Ã£o
                    pred_probs = predictions[1]
                else:
                    predictions = st.session_state.model.predict(X_test, verbose=0)
                    y_pred = np.argmax(predictions, axis=1)
                    pred_probs = predictions
                
                # Calcular mÃ©tricas de forma segura
                accuracy, precision_avg, recall_avg, cm, report = safe_metrics_calculation(y_test, y_pred, class_names)
                
                if accuracy is not None:
                    # Mostrar mÃ©tricas
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("AcurÃ¡cia", f"{accuracy:.2%}")
                    with col2:
                        st.metric("PrecisÃ£o MÃ©dia", f"{precision_avg:.2%}")
                    with col3:
                        st.metric("Recall MÃ©dio", f"{recall_avg:.2%}")
                    
                    # Matriz de confusÃ£o
                    cm_fig = plot_confusion_matrix_safe(cm, class_names)
                    if cm_fig:
                        st.plotly_chart(cm_fig, use_container_width=True)
                    
                    # RelatÃ³rio detalhado
                    if report:
                        st.subheader("ğŸ“‹ RelatÃ³rio Detalhado")
                        report_df = pd.DataFrame(report).transpose()
                        st.dataframe(report_df.round(3))
                    
                    # AnÃ¡lise detalhada por imagem
                    st.subheader("ğŸ” AnÃ¡lise Detalhada")
                    
                    # Usar apenas os arquivos vÃ¡lidos (que foram processados com sucesso)
                    valid_test_files = [test_files[i] for i in valid_test_indices]
                    valid_test_labels = [test_labels[i] for i in valid_test_indices]
                    
                    for i, (file, true_label, pred_label) in enumerate(zip(valid_test_files, y_test, y_pred)):
                        with st.expander(f"Imagem {i+1}: {file.name}"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                file.seek(0)
                                image = Image.open(file)
                                st.image(image, caption="Imagem Original", use_column_width=True)
                            
                            with col2:
                                st.write(f"**Real:** {class_names[true_label]}")
                                st.write(f"**Predito:** {class_names[pred_label]}")
                                
                                # Probabilidades
                                prob_df = pd.DataFrame({
                                    'Classe': class_names,
                                    'Probabilidade': pred_probs[i]
                                })
                                fig = px.bar(prob_df, x='Classe', y='Probabilidade', 
                                           color='Probabilidade', color_continuous_scale='RdYlGn')
                                st.plotly_chart(fig, use_container_width=True)
                                
                                # InterpretaÃ§Ã£o
                                max_prob = np.max(pred_probs[i])
                                if pred_label == 2 and max_prob > 0.8:
                                    st.success("ğŸ›¢ï¸ **ALTA PROBABILIDADE DE RESERVATÃ“RIO**")
                                elif pred_label == 1 and max_prob > 0.6:
                                    st.warning("âš ï¸ **POSSÃVEL RESERVATÃ“RIO**")
                                else:
                                    st.info("â„¹ï¸ **BAIXO POTENCIAL**")
                else:
                    st.error("âŒ NÃ£o foi possÃ­vel calcular as mÃ©tricas")
                
            except Exception as e:
                st.error(f"âŒ Erro na avaliaÃ§Ã£o: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
    
    # PrediÃ§Ã£o individual
    st.header("ğŸ”® AnÃ¡lise de Nova Imagem")
    uploaded_image = st.file_uploader("Carregar imagem sÃ­smica", type=['png', 'jpg', 'jpeg'], key="single")
    
    if uploaded_image and 'model' in st.session_state:
        col1, col2 = st.columns(2)
        
        with col1:
            uploaded_image.seek(0)
            image = Image.open(uploaded_image)
            st.image(image, caption="Imagem para anÃ¡lise", use_column_width=True)
        
        with col2:
            try:
                cnn = st.session_state.cnn
                prediction = cnn.predict_single_image(uploaded_image)
                pred_class = np.argmax(prediction[0])
                confidence = np.max(prediction[0])
                
                st.write(f"**ClassificaÃ§Ã£o:** {class_names[pred_class]}")
                st.write(f"**ConfianÃ§a:** {confidence:.2%}")
                
                # GrÃ¡fico
                prob_df = pd.DataFrame({
                    'Classe': class_names,
                    'Probabilidade': prediction[0]
                })
                fig = px.bar(prob_df, x='Classe', y='Probabilidade', 
                           color='Probabilidade', color_continuous_scale='RdYlGn')
                st.plotly_chart(fig, use_container_width=True)
                
                # InterpretaÃ§Ã£o
                if pred_class == 2 and confidence > 0.8:
                    st.success("ğŸ›¢ï¸ **RESERVATÃ“RIO PROVÃVEL!**")
                elif pred_class == 1 and confidence > 0.6:
                    st.warning("âš ï¸ **POSSÃVEL RESERVATÃ“RIO**")
                else:
                    st.info("â„¹ï¸ **BAIXO POTENCIAL**")
                    
            except Exception as e:
                st.error(f"âŒ Erro na prediÃ§Ã£o: {str(e)}")
    
    # Sidebar informaÃ§Ãµes
    with st.sidebar:
        st.header("ğŸ“– InformaÃ§Ãµes")
        
        if use_masks:
            st.markdown("""
            **ğŸ¯ Modo: SegmentaÃ§Ã£o + ClassificaÃ§Ã£o**
            - Arquitetura U-Net
            - Dupla saÃ­da (pixel + global)
            - Requer masks 1:1 com imagens
            - AnÃ¡lise pixel-wise
            """)
        elif use_transfer_learning:
            st.markdown("""
            **ğŸš€ Modo: Transfer Learning**
            - Base ResNet50 prÃ©-treinada
            - Fine-tuning para dados sÃ­smicos
            - ConvergÃªncia mais rÃ¡pida
            - Melhor generalizaÃ§Ã£o
            """)
        else:
            st.markdown("""
            **ğŸ§  Modo: CNN PadrÃ£o**
            - 4 blocos convolucionais
            - Global Average Pooling
            - RegularizaÃ§Ã£o avanÃ§ada
            - Dropout inteligente
            """)
        
        st.markdown("""
        **ğŸ¨ Classes de AnÃ¡lise:**
        - ğŸ”´ **NÃ£o ReservatÃ³rio**: Estrutura desfavorÃ¡vel
        - ğŸŸ¡ **PossÃ­vel ReservatÃ³rio**: InvestigaÃ§Ã£o necessÃ¡ria
        - ğŸŸ¢ **ProvÃ¡vel ReservatÃ³rio**: Alta probabilidade
        
        **ğŸ“Š MÃ©tricas Calculadas:**
        - AcurÃ¡cia global
        - PrecisÃ£o por classe
        - Recall por classe
        - Matriz de confusÃ£o
        - F1-Score
        """)
        
        # Status do modelo atual
        if 'model' in st.session_state:
            st.subheader("ğŸ¤– Modelo Atual")
            st.write(f"**ParÃ¢metros:** {st.session_state.model.count_params():,}")
            st.write(f"**Camadas:** {len(st.session_state.model.layers)}")
            st.write(f"**Modo:** {'SegmentaÃ§Ã£o' if st.session_state.get('use_masks', False) else 'ClassificaÃ§Ã£o'}")

if __name__ == "__main__":
    main()